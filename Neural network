library(keras)
library(tfdatasets)

#################################################### Importing and normalizing the data

data <- readRDS("Uppsala.data.RDS")

train.data <- data$TrainingSet
test.data <- data$TestSet

set.seed(0)


train.data$eGOS <- train.data$eGOS - 1                                 ##### <-------- Python begins calculations from 0. So eGOS should be from 0 - 7.

train.data$motor <- train.data$motor /10
train.data$pupil <- train.data$pupil / 3
train.data$age <- train.data$age / 100
train.data$CT <- train.data$CT /10

test.data$eGOS <- test.data$eGOS - 1                                 ##### <-------- Python begins calculations from 0. So eGOS should be from 0 - 7.

test.data$motor <- test.data$motor /10
test.data$pupil <- test.data$pupil / 3
test.data$age <- test.data$age / 100
test.data$CT <- test.data$CT /10


###################################### Formatting the training data
train.features <- train.data[, c("motor", "pupil", "age", "CT")]
train.x <- as.matrix(train.features)

train.y <- to_categorical(train.data$eGOS, 8) # <--- antalet labels


###################################### Formatting the testing data
test.features <- test.data[, c("motor", "pupil", "age", "CT")]
test.x <- as.matrix(test.features)

test.y <- to_categorical(test.data$eGOS, 8) # <--- antalet labels

#### x = features och y = labels

################################# Designing the network


model <- keras_model_sequential() 
model %>% 
  layer_dense(units = 6, activation = 'relu', input_shape = c(4)) %>%  # <------- Input shape ?r antalet kolumner i train.x (antal features).
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 6, activation = 'relu') %>%
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 8, activation = 'softmax')

summary(model)

model %>% compile(loss = 'mean_absolute_error', optimizer = optimizer_rmsprop(), metrics = c('mae'))

################################# Training the network


history <- model %>% fit(
  train.x, train.y, 
  epochs = 30, batch_size = 30, 
  validation_split = 0.2
)
plot(history)

######################## Evaluation of the network
evaluate(model, test.x, test.y)


######################################### MSE / MAE
probabilities <- predict(model, test.x)
predicted.egos <- apply(probabilities, 1, which.max)

actual.egos <- as.numeric(test.data$eGOS)

MSE2 <- mean((actual.egos - predicted.egos)^2)
MAE2 <- mean(abs(actual.egos - predicted.egos))
MSE2
MAE2


############# saving model

save_model_hdf5(model, file="NN.h5")

library(keras)
library(tfdatasets)

#################################################### Importing and normalizing the data
model <- load_model_tf('saved_model/neuralnetwork')

data <- read.csv("Data/Uppsaladata.CSV")

set.seed(42)


data$eGOS <- data$eGOS - 1                                 ##### <-------- Python b?rjar r?kna fr?n 0. S? eGOS ska g?r fr?n 0 - 7.

data$motor <- data$motor /10
data$pupil <- data$pupil / 3
data$age <- data$age / 100
data$CT <- data$CT /10

ind <- sample(2, nrow(data), replace=TRUE, prob = c(0.8, 0.2))
train.data <- data[ind==1,]
test.data <- data[ind==2,]

###################################### Formatting the training data
train.features <- train.data[, c("motor", "pupil", "age", "CT")]
train.x <- as.matrix(train.features)

train.y <- to_categorical(train.data$eGOS, 8) # <--- antalet labels


###################################### Formatting the testing data
test.features <- test.data[, c("motor", "pupil", "age", "CT")]
test.x <- as.matrix(test.features)

test.y <- to_categorical(test.data$eGOS, 8) # <--- antalet labels

#### dvs x = features och y = labels

################################# Designing the network


model <- keras_model_sequential() 
model %>% 
  layer_dense(units = 6, activation = 'relu', input_shape = c(4)) %>%  # <------- Input shape ?r antalet kolumner i train.x (antal features).
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 6, activation = 'relu') %>%
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 8, activation = 'softmax')

summary(model)

model %>% compile(loss = 'categorical_crossentropy', optimizer = optimizer_rmsprop(), metrics = c('accuracy'))

################################# Training the network


history <- model %>% fit(
  train.x, train.y, 
  epochs = 30, batch_size = 30, 
  validation_split = 0.2
)
plot(history)

######################## Evaluation of the network
evaluate(model, test.x, test.y)


######################################### MSE / MAE
probabilities <- predict(model, test.x)
predicted.egos <- apply(probabilities, 1, which.max)

actual.egos <- as.numeric(test.data$eGOS)

MSE <- mean((actual.egos - predicted.egos)^2) #MSE for ridge regression
MAE <- mean(abs(actual.egos - predicted.egos))


############################################################
### Make predictions

probabilities <- predict(model, test.x)
predicted.egos <- apply(probabilities, 1, which.max)

actual.egos <- apply(test.y, 1, which.max)

#######################  ROC and AUC for unfavourable / mortality
library(pROC)

AUC.data <- probabilities
prob.unfavourable <- rep(NA,nrow(AUC.data))
for(i in 1:nrow(AUC.data)){
  prob.sum <- sum(AUC.data[i, 1:4])
  prob.unfavourable[i] <- prob.sum
}
prob.favourable <- 1-prob.unfavourable

true.AUC.data <- as.numeric(actual.egos)
was.unfavourable <- true.AUC.data <=4
was.favourable <- !was.unfavourable


prob.mortality <- rep(NA,nrow(AUC.data))
for(i in 1:nrow(AUC.data)){
  prob.sum <- sum(AUC.data[i, 1])
  prob.mortality[i] <- prob.sum
}

true.AUC.data.mortality <- as.numeric(actual.egos)
was.mortality <- true.AUC.data.mortality ==1


ROC.mortality <- roc(predictor = prob.mortality, response = was.mortality)


ROC.unfavourable <- roc(predictor = prob.unfavourable, response = was.unfavourable)

plot(ROC.unfavourable)
AUC.unfavorable <- auc(ROC.unfavourable)

plot(ROC.mortality)
AUC.mortality <- auc(ROC.mortality)


############################################################
### Create confusion matrix

library(ggplot2)
library(reshape)

source("ConfusionMatrix_Count.R")
source("ConfusionMatrix_Normalize.R")
source("ConfusionMatrix_Plot.R")
source("ConfusionMatrix_GOSE.R")

actual.egos.confusion <- as.integer(apply(test.y, 1, which.max))

confusion.matrix <- ConfusionMatrix_GOSE(actual.egos.confusion, predicted.egos)
confusion.matrix$Graph

################################################# Predict using novel data
motor=0.5
pupil=0.333333
age=0.15
length=0.23
motor2=0.6

test.test <- as.matrix(data.frame(motor, pupil, age, length, motor2))
probabilities.test <- predict(model, test.test)
predicted.egos <- apply(probabilities.test, 1, which.max)
predicted.egos


######################################### Testing on Leuven data
Leuvendata <- read.csv("Data/Leuvendata.CSV")


Leuvendata$eGOS <- Leuvendata$eGOS - 1                                 ##### <-------- Python b?rjar r?kna fr?n 0. S? eGOS ska g?r fr?n 0 - 7.

Leuvendata$motor <- Leuvendata$motor /10
Leuvendata$pupil <- Leuvendata$pupil / 3
Leuvendata$age <- Leuvendata$age / 100
Leuvendata$CT <- Leuvendata$CT /10


Leuven.test.set <- Leuvendata

Leuven.test.features <- Leuvendata[, c("motor", "pupil", "age", "CT")]
Leuven.test.x <- as.matrix(test.features)

Leuven.test.y <- to_categorical(Leuven.test.set$eGOS, 8)
Leuven.actual.egos <- apply(Leuven.test.y, 1, which.max)

Leuven.probabilities <- predict(model, Leuven.test.x)
Leuven.predicted.egos <- apply(Leuven.probabilities, 1, which.max)

Leuven.actual.egos <- as.numeric(Leuven.test.set$eGOS)

Leuven.MSE <- mean((Leuven.actual.egos - Leuven.predicted.egos)^2) #MSE for ridge regression
Leuven.MAE <- mean(abs(Leuven.actual.egos - Leuven.predicted.egos))


############################################################# ROC and AUC for unfavourable / mortality
library(pROC)

Leuven.AUC.data <- Leuven.probabilities
Leuven.prob.unfavourable <- rep(NA,nrow(Leuven.AUC.data))
for(i in 1:nrow(Leuven.AUC.data)){
  Leuven.prob.sum <- sum(Leuven.AUC.data[i, 1:4])
  Leuven.prob.unfavourable[i] <- Leuven.prob.sum
}
Leuven.prob.favourable <- 1-Leuven.prob.unfavourable

Leuven.true.AUC.data <- as.numeric(Leuven.actual.egos)
Leuven.was.unfavourable <- Leuven.true.AUC.data <=4
Leuven.was.favourable <- !Leuven.was.unfavourable


Leuven.prob.mortality <- rep(NA,nrow(Leuven.AUC.data))
for(i in 1:nrow(Leuven.AUC.data)){
  Leuven.prob.sum <- sum(Leuven.AUC.data[i, 1])
  Leuven.prob.mortality[i] <- Leuven.prob.sum
}

Leuven.true.AUC.data.mortality <- as.numeric(Leuven.actual.egos)
Leuven.was.mortality <- Leuven.true.AUC.data.mortality ==1


Leuven.ROC.mortality <- roc(predictor = Leuven.prob.mortality, response = Leuven.was.mortality)


Leuven.ROC.unfavourable <- roc(predictor = Leuven.prob.unfavourable, response = Leuven.was.unfavourable)

plot(Leuven.ROC.unfavourable)
Leuven.AUC.unfavorable <- auc(Leuven.ROC.unfavourable)
Leuven.AUC.unfavorable

plot(Leuven.ROC.mortality)
Leuven.AUC.mortality <- auc(Leuven.ROC.mortality)
Leuven.AUC.mortality


#confusion.matrix <- ConfusionMatrix_GOSE(actual.egos, original.predicted)
#confusion.matrix$Graph
########################original predicted without expansion factor
library(ggplot2)
library(reshape)

source("ConfusionMatrix_Count.R")
source("ConfusionMatrix_Normalize.R")
source("ConfusionMatrix_Plot.R")
source("ConfusionMatrix_GOSE.R")

Leuven.probabilities <- predict(model, Leuven.test.x)
Leuven.predicted.egos <- as.integer(apply(Leuven.probabilities, 1, which.max))

Leuven.actual.egos.confusion <- as.integer(apply(Leuven.test.y, 1, which.max))

Leuven.confusion.matrix <- ConfusionMatrix_GOSE(Leuven.actual.egos.confusion, Leuven.predicted.egos)
Leuven.confusion.matrix$Graph


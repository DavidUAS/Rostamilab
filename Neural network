library(keras)
library(tfdatasets)
library(caret)

#################################################### Importing and normalizing the data

data <- readRDS("Uppsala.data.RDS")

data <- data$TrainingSet
data$motor <- factor(data$motor)
data$CT <- factor(data$CT)
data$pupil <- factor(data$pupil)

set.seed(0) # Set the seed for reproducibility

# One hot encoding of categorical features
dummyVars <- dummyVars(~ motor + pupil + CT, data = data)
data_onehot <- as.data.frame(predict(dummyVars, newdata = data))

# Combine the one-hot encoded categorical features with the scaled numerical feature
age <- scale(data$age)
age <- data.frame(age)                  
data_processed <- cbind(data_onehot, age)


# One hot encoding of EGOS
target_onehot <- to_categorical(data$eGOS - 1)


##################### Model creation
create_model <- function() {
  model <- keras_model_sequential() %>%
    layer_dense(units = 1600, activation = 'relu', input_shape = ncol(data_processed)) %>%
    layer_dense(units = 800, activation = 'relu') %>%
    layer_dense(units = 200, activation = 'relu') %>%
    layer_dense(units = 100, activation = 'relu') %>%
    layer_dense(units = 8, activation = 'softmax')
  
  model %>% compile(
    loss = "categorical_crossentropy",
    optimizer = optimizer_rmsprop(),
    metrics = c("accuracy")
  )
  return(model)
}

############################# k-fold cross validation
folds <- createFolds(data$eGOS, k = 10)


accuracy_list <- c()

for (i in seq_along(folds)) {
  cat("Fold", i, "\n")
  
  # Split the data into training and validation sets
  train_indices <- folds[[i]]
  train_data <- as.matrix(data_processed[-train_indices, ])
  train_target <- target_onehot[-train_indices, ]
  val_data <- as.matrix(data_processed[train_indices, ])
  val_target <- target_onehot[train_indices, ]
  
  # Create and train the model
  model <- create_model()
  history <- model %>% fit(
    train_data, train_target,
    epochs = 24,
    batch_size = 64,
    validation_data = list(val_data, val_target),
    verbose = 2
  )
  
  # Evaluate the model on the validation set
  scores <- model %>% evaluate(val_data, val_target, verbose = 0)
  cat("Validation accuracy:", scores[[2]], "\n")
  accuracy_list <- append(accuracy_list, scores[[2]])
}

# Calculate the average accuracy
cat("Average accuracy:", mean(accuracy_list), "\n")

################### Creating the final model

model <- keras_model_sequential() %>%
  layer_dense(units = 1600, activation = 'relu', input_shape = ncol(data_processed)) %>%
  layer_dense(units = 800, activation = 'relu') %>%
  layer_dense(units = 200, activation = 'relu') %>%
  layer_dense(units = 100, activation = 'relu') %>%
  layer_dense(units = 8, activation = 'softmax')

model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_rmsprop(),
  metrics = c("accuracy")
)

summary(model)

x = as.matrix(data_processed)
y = target_onehot

history <- model %>% fit(
  x = x,
  y = y,
  epochs = 24,
  batch_size = 64,
  validation_split = 0
)


################### Evaluation of the network
test.data <- readRDS("Uppsala.data.RDS")
test.data <- test.data$TestSet

test.data$motor <- factor(test.data$motor)
test.data$CT <- factor(test.data$CT)
test.data$pupil <- factor(test.data$pupil)


TestdummyVars <- dummyVars(~ motor + pupil + CT, data = test.data)
Testdata_onehot <- as.data.frame(predict(TestdummyVars, newdata = test.data))
Testage <- scale(test.data$age)
Testage <- data.frame(Testage)                  
test.x <- as.matrix(cbind(Testdata_onehot, Testage))


# Replace 'target' with the name of your target variable
test.y <- to_categorical(test.data$eGOS - 1)


evaluate(model, test.x, test.y)



################### Predictions in test data
probabilities <- predict(model, test.x)
predicted.egos <- apply(probabilities, 1, which.max)
table(predicted.egos)

actual.egos <- as.numeric(test.data$eGOS)
table(actual.egos)


################### Saving the model

save_model_hdf5(model, file="NewestNN.h5")

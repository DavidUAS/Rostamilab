library(ordinalNet)
library(glmnet)
library(ggplot2)

data <- read.csv("Data/Uppsaladata.CSV")


data$eGOS <- as.ordered(data$eGOS)

data$age <- as.numeric(data$age)
data$motor <- as.numeric(data$motor)
data$pupil <- as.numeric(data$pupil)
data$CT <- as.numeric(data$CT)

#str(the.data)
#summary(the.data)


ind <- sample(2, nrow(data), replace=TRUE, prob = c(0.8, 0.2))
train.data <- data[ind==1,]
test.data <- data[ind==2,]


train.dataframe <- train.data[, c("age", "motor", "pupil", "CT")]
x.train <- as.matrix(train.dataframe)

test.dataframe <- test.data[, c("age", "motor", "pupil", "CT")]
x.test <- as.matrix(test.dataframe)

#train.lable <- as.numeric(train.data$eGOS)
y.train <- train.data$eGOS

#test.lable <- as.numeric(test.data$eGOS)
y.test <- test.data$eGOS
numeric.y.test <- as.numeric(y.test) # y.test needs to be numeric for MSE

######################## Ridge regression (alpha = 0)

alpha0.fit <- ordinalNet(x.train, y.train, alpha=0, family=c("cumulative"))

alpha0.predicted <- (predict(alpha0.fit, x.test))#^2 #if 

#alpha0.predicted <- alpha0.predicted
#for (i in 1:nrow(alpha0.predicted)){
#  row.sum <- sum(alpha0.predicted[i, ])
#  alpha0.predicted[i, ] <- alpha0.predicted[i, ]/row.sum
#}

original.egos.0 <- alpha0.predicted
for (i in 1:8){
  original.egos.0[, i] <- original.egos.0[, i] * i
}

original.prediction.0 <- rep(NA, nrow(original.egos.0))

for (i in 1:nrow(original.egos.0)){
  original.prediction.0[i] <- round(sum(original.egos.0[i, ]))
}

head(original.prediction.0)
MSE.0 <- mean((numeric.y.test - original.prediction.0)^2)
MAE.0 <- mean(abs(numeric.y.test - original.prediction.0))

######################## Lasso regression (alpha = 1)

alpha1.fit <- ordinalNet(x.train, y.train, alpha=1, family=c("cumulative"))

alpha1.predicted <- (predict(alpha1.fit, x.test))

original.egos.1 <- alpha1.predicted
for (i in 1:8){
  original.egos.1[, i] <- original.egos.1[, i] * i
}

original.prediction.1 <- rep(NA, nrow(original.egos.1))

for (i in 1:nrow(original.egos.1)){
  original.prediction.1[i] <- round(sum(original.egos.1[i, ]))
}

head(original.prediction.1)
MSE.1 <- mean((numeric.y.test - original.prediction.1)^2)
MAE.1 <- mean(abs(numeric.y.test - original.prediction.1))

####################### Elastic net regression (alpha = 0.5)

alpha0.5.fit <- ordinalNet(x.train, y.train, alpha=0.5, family=c("cumulative"))

alpha0.5.predicted <- (predict(alpha0.5.fit, x.test))

original.egos.0.5 <- alpha0.5.predicted
for (i in 1:8){
  original.egos.0.5[, i] <- original.egos.0.5[, i] * i
}

original.prediction.0.5 <- rep(NA, nrow(original.egos.0.5))

for (i in 1:nrow(original.egos.0.5)){
  original.prediction.0.5[i] <- round(sum(original.egos.0.5[i, ]))
}

head(original.prediction.0.5)
MSE.0.5 <- mean((numeric.y.test - original.prediction.0.5)^2)
MAE.0.5 <- mean(abs(numeric.y.test - original.prediction.0.5))


####################### Optimal elastic net regression (alpha = 0.1)

alpha0.1.fit <- ordinalNet(x.train, y.train, alpha=0.1, family=c("cumulative"))

alpha0.1.predicted <- (predict(alpha0.1.fit, x.test))

original.egos.0.1 <- alpha0.1.predicted
for (i in 1:8){
  original.egos.0.1[, i] <- original.egos.0.1[, i] * i
}

original.prediction.0.1 <- rep(NA, nrow(original.egos.0.1))

for (i in 1:nrow(original.egos.0.1)){
  original.prediction.0.1[i] <- round(sum(original.egos.0.1[i, ]))
}

head(original.prediction.0.1)
MSE.0.1 <- mean((numeric.y.test - original.prediction.0.1)^2)
MAE.0.1 <- mean(abs(numeric.y.test - original.prediction.0.1))

###################### Finding optimal alpha value from 0.0 to 1.0 (combination of lasso and ridge regression) OBS Funkar ej 

list.of.fits <- list()
for (i in 0:10) {
  fit.name <- paste0("alpha", i/10) #creates names of alpha 0/10=0 to 1/10=1
  alpha0.fit <- ordinalNet(x.train, y.train, alpha=i/10, family=c("cumulative"))
  
}

results <- data.frame()
for (i in 0:10) {
  fit.name <- paste0("alpha", i/10)
  
  predicted <-
    predict(list.of.fits[[fit.name]], x=x.test)
  
  mse <- mean((numeric.test.y - predicted)^2)
  
  temp <- data.frame(alpha=i/10, mse=mse, fit.name=fit.name)
  results <- rbind(results, temp)
}

results


###################### Example of probability to prediction

weighted.egos <- alpha0.1.predicted
for (i in 1:8){
  weighted.egos[, i] <- weighted.egos[, i] * i
}

weighted.prediction <- rep(NA, nrow(weighted.egos))

for (i in 1:nrow(weighted.egos)){
  weighted.prediction[i] <- round(sum(weighted.egos[i, ]))
}

head(weighted.prediction)

numeric.test.y <- as.numeric(y.test)
MSE <- mean((numeric.test.y - weighted.prediction)^2)
MAE <- mean(abs(numeric.test.y - weighted.prediction))


##################################### Create confusion matrix

library(ggplot2)
library(reshape)

source("ConfusionMatrix_Count.R")
source("ConfusionMatrix_Normalize.R")
source("ConfusionMatrix_Plot.R")
source("ConfusionMatrix_GOSE.R")

actual.egos <- as.integer(y.test)
predicted.egos <- as.integer(original.prediction.0.1)

confusion.matrix <- ConfusionMatrix_GOSE(actual.egos, predicted.egos)
confusion.matrix$Graph

#######################  ROC and AUC for unfavourable / mortality
library(pROC)

AUC.data <- predict(alpha0.1.fit, x.test)
prob.unfavourable <- rep(NA,nrow(AUC.data))
for(i in 1:nrow(AUC.data)){
  prob.sum <- sum(AUC.data[i, 1:4])
  prob.unfavourable[i] <- prob.sum
}
prob.favourable <- 1-prob.unfavourable

true.AUC.data <- as.numeric(y.test)
was.unfavourable <- true.AUC.data <=4
was.favourable <- !was.unfavourable


prob.mortality <- rep(NA,nrow(AUC.data))
for(i in 1:nrow(AUC.data)){
  prob.sum <- sum(AUC.data[i, 1])
  prob.mortality[i] <- prob.sum
}

true.AUC.data.mortality <- as.numeric(y.test)
was.mortality <- true.AUC.data.mortality ==1


ROC.mortality <- roc(predictor = prob.mortality, response = was.mortality)


ROC.unfavourable <- roc(predictor = prob.unfavourable, response = was.unfavourable)

plot(ROC.unfavourable)
AUC.unfavorable <- auc(ROC.unfavourable)
AUC.unfavorable 

plot(ROC.mortality)
AUC.mortality <- auc(ROC.mortality)
AUC.mortality
######################## Expansion prediction
library(MASS)

expansion.factor <- 1 / (8 - 1)
expanded.predictions.1 <- original.prediction.1 + (original.prediction.1 - 8) * expansion.factor

expanded.predictions.1 <- round(expanded.predictions.1)
expanded.predictions.1[expanded.predictions.1 < 1] <- 1
expanded.predictions.1[expanded.predictions.1 > 8] <- 8

predicted.egos.1 <- as.integer(expanded.predictions.1)

plot(as.factor(expanded.predictions.1))

original.mean.absolute.error <- sum((abs(original.prediction.1 - y.test))) / length(y.test)
adjusted.mean.absolute.error <- sum((abs(predicted.egos.1 - y.test))) / length(y.test)

original.mean.squared.error <- sum((original.prediction.1 - y.test)^2) / length(y.test)
adjusted.mean.squared.error <- sum((predicted.egos.1 - y.test)^2) / length(y.test)


MSE.original.1 <- mean((numeric.y.test - original.prediction.1)^2)
MSE.adjusted.1 <- mean((numeric.y.test - predicted.egos.1)^2)
MAE <- mean(abs(numeric.y.test - weighted.prediction))



######################################### Testing on Leuven data
Leuvendata <- read.csv("Data/Leuvendata.CSV")


Leuvendata$eGOS <- as.ordered(Leuvendata$eGOS)

Leuvendata$age <- as.numeric(Leuvendata$age)
Leuvendata$motor <- as.numeric(Leuvendata$motor)
Leuvendata$pupil <- as.numeric(Leuvendata$pupil)
Leuvendata$length <- as.numeric(Leuvendata$CT)


Leuven.test.data <- Leuvendata

Leuven.test.dataframe <- Leuven.test.data[, c("age", "motor", "pupil", "CT")]
Leuven.x.test <- as.matrix(Leuven.test.dataframe)

#test.lable <- as.numeric(test.data$eGOS)
Leuven.y.test <- Leuven.test.data$eGOS
Leuven.numeric.y.test <- as.numeric(Leuven.y.test) # y.test needs to be numeric for MSE



############################################################# ROC and AUC for unfavourable / mortality
library(pROC)

Leuven.AUC.data <- predict(alpha0.1.fit, Leuven.x.test)
Leuven.prob.unfavourable <- rep(NA,nrow(Leuven.AUC.data))
for(i in 1:nrow(Leuven.AUC.data)){
  prob.sum <- sum(Leuven.AUC.data[i, 1:4])
  Leuven.prob.unfavourable[i] <- prob.sum
}
prob.favourable <- 1-Leuven.prob.unfavourable

Leuven.true.AUC.data <- as.numeric(Leuven.y.test)
Leuven.was.unfavourable <- Leuven.true.AUC.data <=4
Leuven.was.favourable <- !Leuven.was.unfavourable


Leuven.prob.mortality <- rep(NA,nrow(Leuven.AUC.data))
for(i in 1:nrow(Leuven.AUC.data)){
  prob.sum <- sum(Leuven.AUC.data[i, 1])
  Leuven.prob.mortality[i] <- prob.sum
}

Leuven.true.AUC.data.mortality <- as.numeric(Leuven.y.test)
Leuven.was.mortality <- Leuven.true.AUC.data.mortality ==1


Leuven.ROC.mortality <- roc(predictor = Leuven.prob.mortality, response = Leuven.was.mortality)


Leuven.ROC.unfavourable <- roc(predictor = Leuven.prob.unfavourable, response = Leuven.was.unfavourable)

plot(Leuven.ROC.unfavourable)
Leuven.AUC.unfavorable <- auc(Leuven.ROC.unfavourable)
Leuven.AUC.unfavorable 

plot(Leuven.ROC.mortality)
Leuven.AUC.mortality <- auc(ROC.mortality)
Leuven.AUC.mortality


#confusion.matrix <- ConfusionMatrix_GOSE(actual.egos, original.predicted)
#confusion.matrix$Graph


#################################### MSE and MAE
Leuven.alpha0.1.predicted <- predict(alpha0.1.fit, Leuven.x.test)

Leuven.weighted.egos <- Leuven.alpha0.1.predicted
for (i in 1:8){
  Leuven.weighted.egos[, i] <- Leuven.weighted.egos[, i] * i
}

Leuven.weighted.prediction <- rep(NA, nrow(Leuven.weighted.egos))

for (i in 1:nrow(Leuven.weighted.egos)){
  Leuven.weighted.prediction[i] <- round(sum(Leuven.weighted.egos[i, ]))
}

head(Leuven.weighted.prediction)

Leuven.numeric.test.y <- as.numeric(Leuven.y.test)
Leuven.MSE <- mean((Leuven.numeric.test.y - Leuven.weighted.prediction)^2)
Leuven.MAE <- mean(abs(Leuven.numeric.test.y - Leuven.weighted.prediction))

########################original predicted without expansion factor
library(ggplot2)
library(reshape)

source("ConfusionMatrix_Count.R")
source("ConfusionMatrix_Normalize.R")
source("ConfusionMatrix_Plot.R")
source("ConfusionMatrix_GOSE.R")

Leuven.actual.egos <- as.integer(Leuven.y.test)
Leuven.predicted.egos <- as.integer(Leuven.weighted.prediction)

confusion.matrix <- ConfusionMatrix_GOSE(Leuven.actual.egos, Leuven.predicted.egos)
confusion.matrix$Graph
